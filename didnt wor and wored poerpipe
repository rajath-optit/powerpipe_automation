didnt wor and wored poerpipe

To manage and switch between your AWS accounts on a Linux machine, you can store your AWS credentials in a file (like ~/.aws/credentials), and then create a Python script that allows you to switch between the accounts. 

  

Step 1: Store Your AWS Credentials 

First, make sure your AWS credentials are stored in ~/.aws/credentials like this: 

  

[acc1] 

aws_access_key_id = YOUR_ACCESS_KEY_ID_1 

aws_secret_access_key = YOUR_SECRET_ACCESS_KEY_1 

  

[acc2] 

aws_access_key_id = YOUR_ACCESS_KEY_ID_2 

aws_secret_access_key = YOUR_SECRET_ACCESS_KEY_2 

Update Your Configuration File 

Create a configuration file, for example, aws_config.ini: 

  

[aws_account1] 

region = us-east-1 

  

[aws_account2] 

region = ap-south-1 

  
 

Usage: 

Place the aws_config.ini file in the same directory as your script. 

Run the script using python3 switch_aws_account.py. 

Select the desired account, and the script will handle setting the region automatically. 

  

How It Works: 

Configuration File: The script reads the aws_config.ini file to get the region associated with each account. 

Automatic Region Setting: Once you select an account, the script automatically sets the appropriate region. 

  

switch_aws_account.py 

  

import os 

import subprocess 

import configparser 

  

# Define the AWS profile names 

profiles = { 

    '1': 'aws_account1', 

    '2': 'aws_account2' 

} 

  

# Load regions from the config file 

config = configparser.ConfigParser() 

config.read('aws_config.ini') 

  

def switch_account(): 

    print("Available AWS accounts:") 

    for key, value in profiles.items(): 

        print(f"{key}: {value}") 

  

    choice = input("Select the AWS account to activate (1 or 2): ").strip() 

  

    if choice in profiles: 

        selected_profile = profiles[choice] 

        os.environ['AWS_PROFILE'] = selected_profile 

         

        # Set region based on config file 

        region = config[selected_profile]['region'] 

        os.environ['AWS_DEFAULT_REGION'] = region 

         

        print(f"\033[92mAWS account {selected_profile} is now active.\033[0m") 

        print(f"\033[92mAWS region {region} is now set.\033[0m") 

    else: 

        print("\033[91mInvalid selection. Please choose 1 or 2.\033[0m") 

  

def run_command(): 

    while True: 

        command = input("\033[94mEnter a command (or 'exit' to quit): \033[0m").strip() 

  

        if command.lower() == 'exit': 

            break 

  

        result = subprocess.run(command, shell=True) 

        if result.returncode != 0: 

            print(f"\033[91mCommand failed with return code {result.returncode}.\033[0m") 

        else: 

            print(f"\033[92mCommand executed successfully.\033[0m") 

  

if __name__ == "__main__": 

    switch_account() 

    run_command() 

  

  

Example Scenarios: 

If You Selected aws_account1: 

  

After exiting the script, if you run a report generating tool or any AWS CLI command, it will use aws_account1 with the region us-east-1. 

If You Selected aws_account2: 

  

After exiting the script, any commands or tools will use aws_account2 with the region ap-south-1. 

 

 
 
 
if two simultaiousely added... does not work 
 

Docker approch and step that was followed 
 
This document outlines the installation of PowerPipe and Steampipe, as well as the creation and execution of Docker containers for these tools. 

  

--- 

  

# **Setting Up PowerPipe and Steampipe with Docker** 

  

## **1. Installing PowerPipe on Linux** 

  

### **Step 1: Install PowerPipe** 

Open your Linux shell and run the following command to install PowerPipe: 

  

```bash 

sudo /bin/sh -c "$(curl -fsSL https://powerpipe.io/install/powerpipe.sh)" 

``` 

  

### **Step 2: Install Steampipe** 

Next, install Steampipe by running: 

  

```bash 

sudo /bin/sh -c "$(curl -fsSL https://steampipe.io/install/steampipe.sh)" 

``` 

  

### **Step 3: Verify Installation** 

Check the installed version of Steampipe: 

  

```bash 

steampipe -v 

``` 

  

You should see an output like: 

  

```bash 

steampipe version 0.23.5 

``` 

  

### **Step 4: Install the AWS Plugin** 

To install the AWS plugin for Steampipe: 

  

```bash 

steampipe plugin install aws 

``` 

  

### **Step 5: Set Up PowerPipe Mod** 

Create a directory for dashboards and initialize the PowerPipe mod: 

  

```bash 

mkdir dashboards 

cd dashboards 

powerpipe mod init 

powerpipe mod install github.com/turbot/steampipe-mod-aws-compliance 

``` 

  

### **Step 6: Start Services** 

1. **Start Steampipe as a Data Source:** 

   ```bash 

   steampipe service start 

   ``` 

2. **Start the Dashboard Server:** 

   ```bash 

   powerpipe server 

   ``` 

  

### **Step 7: Access Dashboards** 

Once the server is running, browse and view your dashboards at: 

  

``` 

http://localhost:9033 

``` 

  

--- 

  

## **2. Setting Up Docker for PowerPipe and Steampipe** 

  

### **Step 1: Create Dockerfile** 

  

Create a `Dockerfile` in your working directory with the following content: 

  

```Dockerfile 

FROM ubuntu:latest 

  

# Install required packages including curl and tar 

RUN apt-get update && \ 

    apt-get install -y curl tar && \ 

    groupadd -g 1001 powerpipe && \ 

    useradd -u 1001 --create-home --shell /bin/bash --gid powerpipe powerpipe 

  

# Set environment variables 

ENV USER_NAME=powerpipe 

ENV GROUP_NAME=powerpipe 

ENV POWERPIPE_TELEMETRY=none 

  

WORKDIR /home/$USER_NAME/mod 

  

# Download and install PowerPipe 

RUN curl -LO https://github.com/turbot/powerpipe/releases/download/v0.3.1/powerpipe.linux.amd64.tar.gz \ 

  && tar xvzf powerpipe.linux.amd64.tar.gz \ 

  && mv powerpipe /usr/local/bin/powerpipe \ 

  && rm -rf powerpipe.linux.amd64.tar.gz 

  

# Copy mod.pp file to the container and set permissions 

COPY mod.pp /home/${USER_NAME}/mod/mod.pp 

RUN chown -R ${USER_NAME}:${GROUP_NAME} /home/${USER_NAME}/mod 

  

# Run as unprivileged user 

USER $USER_NAME 

ENV USER=$USER_NAME 

RUN powerpipe mod install /home/${USER_NAME}/mod/mod.pp 

  

# Copy and set up entrypoint 

COPY entrypoint.sh /entrypoint.sh 

ENTRYPOINT [ "/bin/bash", "/entrypoint.sh" ] 

``` 

  

### **Step 2: Create Entrypoint Script** 

  

Create an `entrypoint.sh` file with the following content: 

  

```bash 

#!/usr/bin/env bash 

set -Eeo pipefail 

# copy bundled files to writeable location 

SRC_DIR="$HOME/.powerpipe" 

RUN_DIR="$HOME/run/.powerpipe" 

POWERPIPE_INSTALL_DIR="${RUN_DIR}" 

mkdir -p "${HOME}/run" 

cp -a "${SRC_DIR}" "${RUN_DIR}" 

exec "$@" 

``` 

  

### **Step 3: Build the Docker Image** 

  

Build the Docker image using the following command: 

  

```bash 

docker build -t my-powerpipe-image . 

``` 

  

### **Step 4: Run the Docker Container** 

  

Run the Docker container: 

  

```bash 

docker run --name my-powerpipe-container -d my-powerpipe-image 

``` 

  

### **Step 5: Running Steampipe in Docker** 

  

To pull and run Steampipe as a Docker container: 

  

```bash 

docker pull turbot/steampipe 

  

docker run --name my-steampipe-container \ 

  -e AWS_ACCESS_KEY_ID=your-access-key-id \ 

  -e AWS_SECRET_ACCESS_KEY=your-secret-access-key \ 

  -p 9194:9194 \ 

  -d turbot/steampipe 

``` 

  

### **Step 6: Accessing the Dockerized Services** 

  

- **Steampipe**: Access Steampipe by connecting to the mapped port (e.g., `http://localhost:9194`). 

- **PowerPipe**: You can access the PowerPipe dashboard server at `http://localhost:9033`. 

 Outcome 
 
